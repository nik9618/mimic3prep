{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kanit/mimic3/DB_22000_2'\n",
    "block = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import psycopg2\n",
    "import datetime\n",
    "import sys\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='mimic' user='mimic' host='localhost' password='meladymimic315'\")\n",
    "except:\n",
    "    print \"I am unable to connect to the database\"\n",
    "print 'connection established'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# load admissionID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_adm = np.load('res/admission_ids.npy').tolist()\n",
    "admission_ids = _adm['admission_ids']\n",
    "admission_ids_txt = _adm['admission_ids_txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load filtered itemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = np.load('res/filtered_input.npy').tolist()\n",
    "valid_input = v['id']\n",
    "valid_input_unit = v['unit']\n",
    "\n",
    "v = np.load('res/filtered_output.npy').tolist()\n",
    "valid_output = v['id']\n",
    "\n",
    "v = np.load('res/filtered_chart.npy').tolist()\n",
    "valid_chart = v['id']\n",
    "valid_chart_unit = v['unit']\n",
    "\n",
    "v = np.load('res/filtered_chart_cate.npy').tolist()\n",
    "valid_chart_cate = v['id']\n",
    "\n",
    "v = np.load('res/filtered_lab.npy').tolist()\n",
    "valid_lab = v['id']\n",
    "valid_lab_unit = v['unit']\n",
    "\n",
    "v = np.load('res/filtered_lab_num.npy').tolist()\n",
    "valid_lab_num = v['id']\n",
    "valid_lab_num_unit = v['unit']\n",
    "\n",
    "v = np.load('res/filtered_lab_cate.npy').tolist()\n",
    "valid_lab_cate = v['id']\n",
    "\n",
    "v = np.load('res/filtered_microbio.npy').tolist()\n",
    "valid_microbio = v['id']\n",
    "\n",
    "v = np.load('res/filtered_prescript.npy').tolist()\n",
    "valid_prescript = v['id']\n",
    "valid_prescript_unit = v['unit']\n",
    "allids = valid_input+valid_output+valid_chart+valid_chart_cate+valid_lab+valid_lab_num+valid_lab_cate+valid_microbio+valid_prescript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list final number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_input) = 277\n",
      "len(valid_output) = 68\n",
      "len(valid_chart) = 660\n",
      "len(valid_chart_cate) = 1\n",
      "len(valid_lab) = 372\n",
      "len(valid_lab_num) = 54\n",
      "len(valid_lab_cate) = 231\n",
      "len(valid_microbio) = 9085\n",
      "len(valid_prescript) = 2371\n",
      "\n",
      "len(allids) = 13119\n"
     ]
    }
   ],
   "source": [
    "print 'len(valid_input) = '+ str(len(valid_input))\n",
    "print 'len(valid_output) = '+ str(len(valid_output))\n",
    "print 'len(valid_chart) = '+ str(len(valid_chart))\n",
    "print 'len(valid_chart_cate) = '+ str(len(valid_chart_cate))\n",
    "print 'len(valid_lab) = '+ str(len(valid_lab))\n",
    "print 'len(valid_lab_num) = '+ str(len(valid_lab_num))\n",
    "print 'len(valid_lab_cate) = '+ str(len(valid_lab_cate))\n",
    "print 'len(valid_microbio) = '+ str(len(valid_microbio))\n",
    "print 'len(valid_prescript) = '+ str(len(valid_prescript))\n",
    "print '\\nlen(allids) = '+ str(len(allids) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admission_ids_txt =\"\"\n",
    "for t in admission_ids:\n",
    "    admission_ids_txt += str(t)+\",\"\n",
    "admission_ids_txt=admission_ids_txt[0:-1]\n",
    "\n",
    "valid_input_txt =\"\"\n",
    "for t in valid_input:\n",
    "    valid_input_txt += str(t)+\",\"\n",
    "valid_input_txt=valid_input_txt[0:-1]\n",
    "\n",
    "valid_output_txt =\"\"\n",
    "for t in valid_output:\n",
    "    valid_output_txt += str(t)+\",\"\n",
    "valid_output_txt=valid_output_txt[0:-1]\n",
    "\n",
    "valid_chart_txt =\"\"\n",
    "for t in valid_chart:\n",
    "    valid_chart_txt += str(t)+\",\"\n",
    "valid_chart_txt=valid_chart_txt[0:-1]\n",
    "\n",
    "valid_chart_cate_txt =\"\"\n",
    "for t in valid_chart_cate:\n",
    "    valid_chart_cate_txt += str(t)+\",\"\n",
    "valid_chart_cate_txt=valid_chart_cate_txt[0:-1]\n",
    "\n",
    "valid_lab_txt =\"\"\n",
    "for t in valid_lab:\n",
    "    valid_lab_txt += str(t)+\",\"\n",
    "valid_lab_txt=valid_lab_txt[0:-1]\n",
    "\n",
    "valid_lab_num_txt =\"\"\n",
    "for t in valid_lab_num:\n",
    "    valid_lab_num_txt += str(t)+\",\"\n",
    "valid_lab_num_txt=valid_lab_num_txt[0:-1]\n",
    "\n",
    "valid_lab_cate_txt =\"\"\n",
    "for t in valid_lab_cate:\n",
    "    valid_lab_cate_txt += str(t)+\",\"\n",
    "valid_lab_cate_txt=valid_lab_cate_txt[0:-1]\n",
    "\n",
    "valid_microbio_txt =\"'\"\n",
    "for t in valid_microbio:\n",
    "    valid_microbio_txt += str(t)+\"','\"\n",
    "valid_microbio_txt=valid_microbio_txt[0:-2]\n",
    "\n",
    "valid_prescript_txt =\"'\"\n",
    "for t in valid_prescript:\n",
    "    valid_prescript_txt += str(t)+\"','\"\n",
    "valid_prescript_txt=valid_prescript_txt[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index =0\n",
    "map_itemid_index = {}\n",
    "allitem = valid_output + valid_input + valid_chart + valid_chart_cate + valid_lab + valid_lab_num + valid_lab_cate + valid_microbio + valid_prescript\n",
    "allitem_unit = ['NOCHECK']*len(valid_output) + valid_input_unit + valid_chart_unit +['NOCHECK'] + valid_lab_unit + valid_lab_num_unit+ ['NOCHECK']*len(valid_lab_cate)+ ['NOCHECK']*len(valid_microbio) + valid_prescript_unit\n",
    "for i in range(len(allitem_unit)):\n",
    "    allitem_unit[i] = allitem_unit[i].replace(' ','').lower()\n",
    "assert len(allitem) == len(allitem_unit)\n",
    "for ai in allitem:\n",
    "    map_itemid_index[ai] = index\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical feature, Here we give a number for each different value. For example, A, B, C, D, we assign A to 1, B to 2, C to 3, D to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DONE\n"
     ]
    }
   ],
   "source": [
    "catedict = {}\n",
    "\n",
    "for i in valid_chart_cate:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT distinct value FROM mimiciii.chartevents WHERE itemid = '+ str(i) +' and hadm_id in ('+admission_ids_txt+')')\n",
    "    distinctval = cur.fetchall()\n",
    "    mapping = {};\n",
    "    ct = 1;\n",
    "    for d in distinctval:\n",
    "        mapping[d[0]]= ct;\n",
    "        ct+=1;\n",
    "    catedict[i] = mapping\n",
    "    print '.',\n",
    "    \n",
    "for i in valid_lab_cate:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT distinct value FROM mimiciii.labevents WHERE itemid = '+ str(i) +' and hadm_id in ('+admission_ids_txt+')')\n",
    "    distinctval = cur.fetchall()\n",
    "    mapping = {};\n",
    "    ct = 1;\n",
    "    for d in distinctval:\n",
    "        mapping[d[0]]= ct;\n",
    "        ct+=1;\n",
    "    catedict[i] = mapping\n",
    "    print '.',\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This method is the main part of this file.\n",
    "input : \n",
    "- aid = admission ID that we would like to process,\n",
    "- f = file to print out log. (log can be very long)\n",
    "\n",
    "output: \n",
    "- matrix represent the all events in admission.\n",
    "\n",
    "### There are 2 stage of processing.\n",
    "#### 1. gathering all events\n",
    "\n",
    "In this step, we have an array called whole data, it keep all the events from every tables. For each table we query the observations for the admission aid, we place it into this format.\n",
    "\n",
    "[type of event, time after admission (in seconds), list(time,itemid,values,uom)]\n",
    "\n",
    "for example : ['oe',1,(01/01/2010 1pm, 1234, 15,'mL')]\n",
    "It means the records is from outputevent table, 1 second after admission time, the event is at 1/1/2010 1pm, itemid=1234, output is 15 mL.\n",
    "\n",
    "once we have the array. we can know all the distinct timestep, then we can know the size of the matrix that we have to prepare.\n",
    "\n",
    "we build the mapping on time to row number, so that given a time we can exactly know where to put the value in.\n",
    "\n",
    "**In this step, we also preprocess some number.** In this part, we make sure that every number passed to step 2 are actually numerical. For example, if the input value is '0-2', we will average it so the value will be equal to 1. To parse the number, we write our own function, which is in utils.py.\n",
    "\n",
    "**Also if the unit of measurement are not match with the main uom, then we try to convert it**. If it is not convertable, then we discard that observation. The conversion table is in utils.py file.\n",
    "\n",
    "#### 2. place to the array\n",
    "\n",
    "Basically, just place everything on the call corresponding to the time and itemid of that observations.\n",
    "\n",
    "We also need to beware that if there are multiple observation of the same itemid at the same time. We need to take some action (sum the value or average the value). It depends on the variables, if it is from chartevent, we will average them. If it is from outputevents, we will sum them up.\n",
    "\n",
    "Finally, We got the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing(aid,f=sys.stdout):\n",
    "    \n",
    "    # init array to keep dropped observation\n",
    "    dropobservation = [0] * len(allitem)\n",
    "    \n",
    "    # admission\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT * FROM mimiciii.admissions WHERE hadm_id='+str(aid))\n",
    "    admission = cur.fetchone()\n",
    "    admitdate = admission[3]\n",
    "    if(admitdate == None):\n",
    "        return None;\n",
    "    writeline(f,\"aid : \"+ str(aid))\n",
    "    wholedata = []\n",
    "\n",
    "    #preprocess inputevents\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT starttime,itemid,amount,amountuom FROM mimiciii.inputevents_mv WHERE amount>0 and hadm_id = '+str(aid)+' and itemid in ('+valid_input_txt+')')\n",
    "    inputevents = cur.fetchall()\n",
    "    for ie in inputevents : \n",
    "        \n",
    "        #check date\n",
    "        if(ie[0] == None):\n",
    "            writeline(f,'ie date 0 : ' + \" : \"+str(ie))\n",
    "            dropobservation[map_itemid_index[ie[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(ie[2] == None):\n",
    "            writeline(f,'INPUT None value :' + str(ie))\n",
    "            dropobservation[map_itemid_index[ie[1]]] +=1\n",
    "            continue;\n",
    "\n",
    "        #tuple to list\n",
    "        ie = list(ie)\n",
    "        \n",
    "        #check unit\n",
    "        currentunit = ie[3].replace(' ','').lower()\n",
    "        if( currentunit == allitem_unit[map_itemid_index[ie[1]]] or currentunit == ''):\n",
    "            pass;\n",
    "        else:    \n",
    "            gr = findUnitGroup(currentunit)\n",
    "            if(allitem_unit[map_itemid_index[ie[1]]] in gr):\n",
    "                targetunit = allitem_unit[map_itemid_index[ie[1]]];\n",
    "                ie[2] = ie[2] / gr[currentunit] * gr[targetunit]\n",
    "            else:\n",
    "                writeline(f,'INPUT Unit not match : ' + ie[3].replace(' ','').lower() + ', orig=' + allitem_unit[map_itemid_index[ie[1]]] + \" : \"+str(ie))\n",
    "                dropobservation[map_itemid_index[ie[1]]] +=1\n",
    "                continue;\n",
    "\n",
    "        #discard none value\n",
    "        if(ie[2] == None):\n",
    "            writeline(f,'INPUT None value :' + str(ie))\n",
    "            dropobservation[map_itemid_index[ie[1]]] +=1\n",
    "            continue;\n",
    "            \n",
    "        wholedata.append(['ie',(ie[0]-admitdate).total_seconds(),list(ie)])\n",
    "\n",
    "    #preprocess outputevents\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,value FROM mimiciii.outputevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_output_txt+')')\n",
    "    outputevents = cur.fetchall()\n",
    "    for oe in outputevents : \n",
    "        #check date\n",
    "        if(oe[0] == None):\n",
    "            writeline(f,'oe date 0 : ' + \" : \"+str(oe))\n",
    "            dropobservation[map_itemid_index[oe[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(oe[2] == None):\n",
    "            writeline(f,'OUTPUT None value :' + str(oe))\n",
    "            dropobservation[map_itemid_index[oe[1]]] +=1\n",
    "            continue;\n",
    "            \n",
    "        # no need to check unit all is mL\n",
    "        wholedata.append(['oe',(oe[0]-admitdate).total_seconds(),list(oe)])\n",
    "\n",
    "    #preprocess chartevents\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,valuenum,valueuom FROM mimiciii.chartevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_chart_txt+')')\n",
    "    chartevents = cur.fetchall()\n",
    "    for ce in chartevents: \n",
    "        \n",
    "        #check date\n",
    "        if(ce[0] == None):\n",
    "            writeline(f,'ce date 0 : ' + \" : \"+str(ce))\n",
    "            dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(ce[2] == None):\n",
    "            writeline(f,'CHART None value :' + str(ce))\n",
    "            dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #tuple to list\n",
    "        ce = list(ce)\n",
    "        \n",
    "        #check unit\n",
    "        currentunit = ce[3].replace(' ','').lower()\n",
    "        if( currentunit == allitem_unit[map_itemid_index[ce[1]]] or currentunit == ''):\n",
    "            pass;\n",
    "        else:    \n",
    "            gr = findUnitGroup(currentunit)\n",
    "            if(allitem_unit[map_itemid_index[ce[1]]] in gr):\n",
    "                targetunit = allitem_unit[map_itemid_index[ce[1]]];\n",
    "                ce[2] = ce[2] / gr[currentunit] * gr[targetunit]\n",
    "                writeline(f,'******************************************' + str(ce))\n",
    "            else:\n",
    "                writeline(f,'CHART Unit not match : ' + ce[3].replace(' ','').lower() + ', orig=' + allitem_unit[map_itemid_index[ce[1]]] + ' : ' + \" : \"+str(ce))\n",
    "                dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "                continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(ce[2] == None):\n",
    "            writeline(f,'CHART None value :' + str(ce))\n",
    "            dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        wholedata.append(['ce',(ce[0]-admitdate).total_seconds(),list(ce)])\n",
    "\n",
    "        \n",
    "    #preprocess chartevents cate\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,value,valueuom FROM mimiciii.chartevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_chart_cate_txt+')')\n",
    "    chartevents = cur.fetchall()\n",
    "    for ce in chartevents: \n",
    "        \n",
    "        #check date\n",
    "        if(ce[0] == None):\n",
    "            writeline(f,'cecate date 0 : ' + \" : \"+str(ce))\n",
    "            dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(ce[2] == None):\n",
    "            writeline(f,'cecate None value :' + str(ce))\n",
    "            dropobservation[map_itemid_index[ce[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #tuple to list\n",
    "        ce = list(ce)\n",
    "        \n",
    "        #map to num\n",
    "        ce[2] = catedict[ce[1]][ce[2]]\n",
    "        wholedata.append(['cecate',(ce[0]-admitdate).total_seconds(),list(ce)])\n",
    "\n",
    "            \n",
    "    #preprocess labevents\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,valuenum,valueuom FROM mimiciii.labevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_lab_txt+')')\n",
    "    labevents = cur.fetchall()\n",
    "    for le in labevents :    \n",
    "        #check date\n",
    "        if(le[0] == None):\n",
    "            writeline(f,'le date 0 : ' + \" : \"+str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "\n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            writeline(f,'LAB None value :' + str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "    \n",
    "        #tuple to list\n",
    "        le = list(le)\n",
    "        \n",
    "        #check unit\n",
    "        currentunit = le[3].replace(' ','').replace('<','').replace('>','').replace('=','').lower()\n",
    "        if( currentunit == allitem_unit[map_itemid_index[le[1]]] or currentunit == ''):\n",
    "            pass;\n",
    "        else:    \n",
    "            gr = findUnitGroup(currentunit)\n",
    "            \n",
    "            # try to convert if unit is different and convertible.\n",
    "            if(allitem_unit[map_itemid_index[le[1]]] in gr):\n",
    "                targetunit = allitem_unit[map_itemid_index[le[1]]];\n",
    "                le[2] = le[2] / gr[currentunit] * gr[targetunit]\n",
    "            else:\n",
    "                writeline(f,'LAB Unit not match : ' + le[3].replace(' ','').lower() + ', orig=' + allitem_unit[map_itemid_index[le[1]]] + \" : \" + \" : \"+str(le))\n",
    "                dropobservation[map_itemid_index[le[1]]] +=1\n",
    "                continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            writeline(f,'LAB None value :' + str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        wholedata.append(['le',(le[0]-admitdate).total_seconds(),list(le)])\n",
    "        \n",
    "    #preprocess labevents_num\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,value,valueuom FROM mimiciii.labevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_lab_num_txt+')')\n",
    "    labevents = cur.fetchall()\n",
    "    for le in labevents :    \n",
    "        \n",
    "        #tuple to list\n",
    "        le = list(le)\n",
    "        \n",
    "        #translate values\n",
    "        le[2] = parseNum(le[2]);\n",
    "        \n",
    "        #check date\n",
    "        if(le[0] == None):\n",
    "            writeline(f,'lenum date 0 : ' + \" : \"+str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "\n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            writeline(f,'lenum None value :' + str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "    \n",
    "        #check unit\n",
    "        currentunit = le[3].replace(' ','').replace('<','').replace('>','').replace('=','').lower()\n",
    "        if( currentunit == allitem_unit[map_itemid_index[le[1]]] or currentunit == ''):\n",
    "            pass;\n",
    "        else:    \n",
    "            gr = findUnitGroup(currentunit)\n",
    "            # try to convert if unit is different and convertible.\n",
    "            if(allitem_unit[map_itemid_index[le[1]]] in gr):\n",
    "                targetunit = allitem_unit[map_itemid_index[le[1]]];\n",
    "                le[2] = le[2] / gr[currentunit] * gr[targetunit]\n",
    "            else:\n",
    "                writeline(f,'lenum Unit not match : ' + le[3].replace(' ','').lower() + ', orig=' + allitem_unit[map_itemid_index[le[1]]] + \" : \" + \" : \"+str(le))\n",
    "                dropobservation[map_itemid_index[le[1]]] +=1\n",
    "                continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            writeline(f,'lenum None value :' + str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        wholedata.append(['lenum',(le[0]-admitdate).total_seconds(),list(le)])\n",
    "\n",
    "    #preprocess chartevents num\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT charttime,itemid,value,valueuom FROM mimiciii.labevents WHERE hadm_id = '+str(aid)+' and itemid in ('+valid_lab_cate_txt+')')\n",
    "    labevents = cur.fetchall()\n",
    "    for le in labevents :    \n",
    "        \n",
    "        #tuple to list\n",
    "        le = list(le)\n",
    "        \n",
    "        #check date\n",
    "        if(le[0] == None):\n",
    "            writeline(f,'lecate date 0 : ' + \" : \"+str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "\n",
    "        #discard none value\n",
    "        if(le[2] == None):\n",
    "            writeline(f,'lecate None value :' + str(le))\n",
    "            dropobservation[map_itemid_index[le[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        le[2] = catedict[le[1]][le[2]];\n",
    "        \n",
    "        wholedata.append(['lecate',(le[0]-admitdate).total_seconds(),list(le)])\n",
    "        \n",
    "        \n",
    "    #preprocess prescriptions\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT starttime,formulary_drug_cd,dose_val_rx,dose_unit_rx FROM mimiciii.prescriptions WHERE hadm_id = '+str(aid)+' and formulary_drug_cd in ('+valid_prescript_txt+')')\n",
    "    presevents = cur.fetchall()\n",
    "    for pe in presevents: \n",
    "        #checkdate\n",
    "        if(pe[0] == None):\n",
    "            writeline(f,'pe date 0 : '  + \" : \"+str(pe))\n",
    "            dropobservation[map_itemid_index[pe[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        #tuple to list\n",
    "        pe = list(pe)\n",
    "        \n",
    "        # formatting the value\n",
    "        dose = pe[2]\n",
    "        dose = dose.replace(',','').replace(' ','')\n",
    "        numVal = None;\n",
    "        try:\n",
    "            numVal = float(dose)\n",
    "        except:\n",
    "            if(len(dose.split('-'))==2):\n",
    "                strs = dose.split('-')\n",
    "                try:\n",
    "                    numVal = (float(strs[0]) + float(strs[1]))/2.0\n",
    "                except:\n",
    "                    writeline(f,'pe parse fail : '  + \" : \"+str(pe))\n",
    "                    dropobservation[map_itemid_index[pe[1]]] +=1\n",
    "                    continue;\n",
    "            else:\n",
    "                writeline(f,'pe parse fail : '  + \" : \"+str(pe))\n",
    "                dropobservation[map_itemid_index[pe[1]]] +=1\n",
    "                continue;\n",
    "        \n",
    "        pe[2] = numVal;\n",
    "        \n",
    "        #discard none value\n",
    "        if(pe[2] == None):\n",
    "            writeline(f,'PRES None value :' + str(pe))\n",
    "            dropobservation[map_itemid_index[pe[1]]] +=1\n",
    "            continue;\n",
    "            \n",
    "        #check unit\n",
    "        currentunit = pe[3].replace(' ','').lower()\n",
    "        if( currentunit == allitem_unit[map_itemid_index[pe[1]]] or currentunit == ''):\n",
    "            pass;\n",
    "        else:    \n",
    "            gr = findUnitGroup(currentunit)\n",
    "            if(allitem_unit[map_itemid_index[pe[1]]] in gr):\n",
    "                targetunit = allitem_unit[map_itemid_index[pe[1]]];\n",
    "                pe[2] = pe[2] / gr[currentunit] * gr[targetunit]\n",
    "            else:\n",
    "                writeline(f,'PRES Unit not match : ' + pe[3].replace(' ','').lower() + ', orig=' + allitem_unit[map_itemid_index[pe[1]]]+ \" : \"+str(pe))\n",
    "                continue;\n",
    "\n",
    "        #discard none value\n",
    "        if(pe[2] == None):\n",
    "            writeline(f, 'PRES None value :' + str(pe))\n",
    "            dropobservation[map_itemid_index[pe[1]]] +=1\n",
    "            continue;\n",
    "        \n",
    "        wholedata.append(['pe',(pe[0]-admitdate).total_seconds(),list(pe)])\n",
    "\n",
    "    #micro biology preprocess\n",
    "    for mid in valid_microbio:\n",
    "        mid = mid.replace('(','').replace(')','')\n",
    "        m = mid.split(',')\n",
    "        cur = conn.cursor()\n",
    "        sql = 'SELECT charttime,(spec_itemid,org_itemid,ab_itemid),dilution_text,\\'uom\\' FROM mimiciii.microbiologyevents WHERE hadm_id = '+str(aid)\n",
    "        \n",
    "        if(m[0] == ''):\n",
    "            sql += ' and spec_itemid is null'\n",
    "        else:\n",
    "            sql += ' and spec_itemid = '+m[0]\n",
    "    \n",
    "        if(m[1] == ''):\n",
    "            sql += ' and org_itemid is null'\n",
    "        else:\n",
    "            sql += ' and org_itemid = '+m[1]\n",
    "        \n",
    "        if(m[2] == ''):\n",
    "            sql += ' and ab_itemid is null'\n",
    "        else:\n",
    "            sql += ' and ab_itemid = '+m[2]\n",
    "\n",
    "        cur.execute(sql)\n",
    "        microevents = cur.fetchall()\n",
    "        for me in microevents: \n",
    "            \n",
    "            #checkdate\n",
    "            if(me[0] == None):\n",
    "                writeline(f,'me date 0 : '+ \" : \"+str(me))\n",
    "                dropobservation[map_itemid_index[me[1]]] +=1\n",
    "                continue;\n",
    "\n",
    "            #discard none value\n",
    "            if(me[2] == None):\n",
    "                writeline(f,'MICRO None value :' + str(me))\n",
    "                dropobservation[map_itemid_index[me[1]]] +=1\n",
    "                continue;\n",
    "            \n",
    "            #tuple to list\n",
    "            me = list(me)\n",
    "            \n",
    "            #formatting \n",
    "            dose = me[2]\n",
    "            dose = dose.replace('<','').replace('>','').replace('=','')\n",
    "            numVal = None;\n",
    "            if(dose == ''):\n",
    "                writeline(f,'me parse fail : '+ \" : \"+str(me))\n",
    "                dropobservation[map_itemid_index[me[1]]] +=1\n",
    "                continue;\n",
    "                \n",
    "            try:\n",
    "                numVal = float(dose)\n",
    "            except:\n",
    "                writeline(f,'me parse fail : '+ \" : \"+str(me))\n",
    "                dropobservation[map_itemid_index[me[1]]] +=1\n",
    "                continue;\n",
    "\n",
    "            me[2]=numVal;\n",
    "            \n",
    "            #discard none value; check again after process\n",
    "            if(me[2] == None):\n",
    "                writeline(f,'MICRO None value :' + str(me))\n",
    "                dropobservation[map_itemid_index[me[1]]] +=1\n",
    "                continue;\n",
    "                    \n",
    "            wholedata.append(['me',(me[0]-admitdate).total_seconds(),list(me)])\n",
    "\n",
    "    # sort by time\n",
    "    wholedata = sorted(wholedata, key=itemgetter(1))\n",
    "\n",
    "    # mapping time to row\n",
    "    map_time_index = {}\n",
    "    index = 0;\n",
    "    for wd in wholedata:\n",
    "        if(wd[1] not in map_time_index):\n",
    "            map_time_index[wd[1]] = index\n",
    "            index += 1;\n",
    "\n",
    "    # STEP 2 \n",
    "\n",
    "    # date input output labevent prescript\n",
    "    D = 2+len(valid_input)+len(valid_output)+len(valid_chart)+len(valid_chart_cate)+len(valid_lab)+len(valid_lab_num)+len(valid_lab_cate)+len(valid_microbio)+len(valid_prescript)\n",
    "\n",
    "    patient = [[None for i in range(D)] for j in range(len(map_time_index))]\n",
    "    numtodivide = [[0 for i in range(D-2)] for j in range(len(map_time_index))]\n",
    "    writeline(f,'len(wholedata) = '+str(len(wholedata)))\n",
    "    writeline(f, 'D = '+str(D))\n",
    "    writeline(f,'len(patient) = '+str(len(patient)) +' timesteps')\n",
    "\n",
    "    for wd in wholedata:\n",
    "\n",
    "        assert patient[ map_time_index[wd[1]] ][D-2] == None or patient[ map_time_index[wd[1]] ][D-2] == wd[1]\n",
    "        patient[ map_time_index[wd[1]] ][D-2] = wd[1]\n",
    "        patient[ map_time_index[wd[1]] ][D-1] = aid\n",
    "\n",
    "        if(wd[0] ==  'ie' or wd[0] ==  'oe' or wd[0] ==  'pe'):\n",
    "            if(patient[map_time_index[wd[1]]][map_itemid_index[wd[2][1]]] ==None):\n",
    "                patient[map_time_index[wd[1]]][map_itemid_index[wd[2][1]]] = wd[2][2] \n",
    "            else: \n",
    "                patient[map_time_index[wd[1]]][map_itemid_index[wd[2][1]]] += wd[2][2]\n",
    "\n",
    "        if(wd[0] ==  'le' or wd[0] == 'ce' or wd[0] == 'me' or wd[0] ==  'lenum'):\n",
    "            if(patient[map_time_index[wd[1]]] [map_itemid_index[wd[2][1]]] == None):\n",
    "                patient[  map_time_index[wd[1]]  ][  map_itemid_index[wd[2][1]]  ] = wd[2][2]\n",
    "                numtodivide[map_time_index[wd[1]]  ]  [  map_itemid_index[wd[2][1]] ] = 1\n",
    "            else: \n",
    "                patient[map_time_index[wd[1]]][map_itemid_index[wd[2][1]]] += wd[2][2]\n",
    "                numtodivide[ map_time_index[wd[1]]  ] [   map_itemid_index[wd[2][1]] ] += 1\n",
    "        \n",
    "        if(wd[0] == 'cecate' or wd[0] == 'lecate'):\n",
    "            if(patient[map_time_index[wd[1]]] [map_itemid_index[wd[2][1]]] == None):\n",
    "                patient[  map_time_index[wd[1]]  ][  map_itemid_index[wd[2][1]]  ] = wd[2][2]\n",
    "            else: \n",
    "                print 'DUPLICATED :',wd\n",
    "                dropobservation[map_itemid_index[wd[2][1]]] +=1\n",
    "        \n",
    "    for i in range(len(map_time_index)):\n",
    "        for j in range(D-2):\n",
    "            if(numtodivide[i][j] == 0): continue;\n",
    "            patient[i][j] /= numtodivide[i][j]\n",
    "    \n",
    "    return (patient,dropobservation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 185131\n",
      "1 : 164444\n",
      "2 : 191210\n",
      "3 : 197882\n",
      "DUPLICATED : ['cecate', 46200.0, [datetime.datetime(2129, 9, 19, 9, 45), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 46200.0, [datetime.datetime(2129, 9, 19, 9, 45), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 247800.0, [datetime.datetime(2129, 9, 21, 17, 45), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 247800.0, [datetime.datetime(2129, 9, 21, 17, 45), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 305580.0, [datetime.datetime(2129, 9, 22, 9, 48), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 305580.0, [datetime.datetime(2129, 9, 22, 9, 48), 223758, 2, '']]\n",
      "4 : 140212\n",
      "DUPLICATED : ['cecate', 34980.0, [datetime.datetime(2180, 4, 19, 7, 12), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 34980.0, [datetime.datetime(2180, 4, 19, 7, 12), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 35160.0, [datetime.datetime(2180, 4, 19, 7, 15), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 35160.0, [datetime.datetime(2180, 4, 19, 7, 15), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 66180.0, [datetime.datetime(2180, 4, 19, 15, 52), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 66180.0, [datetime.datetime(2180, 4, 19, 15, 52), 223758, 2, '']]\n",
      "5 : 149609\n",
      "DUPLICATED : ['cecate', 420.0, [datetime.datetime(2121, 3, 3, 13, 43), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 420.0, [datetime.datetime(2121, 3, 3, 13, 43), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 90240.0, [datetime.datetime(2121, 3, 4, 14, 40), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 90240.0, [datetime.datetime(2121, 3, 4, 14, 40), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 90240.0, [datetime.datetime(2121, 3, 4, 14, 40), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 90240.0, [datetime.datetime(2121, 3, 4, 14, 40), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 350640.0, [datetime.datetime(2121, 3, 7, 15, 0), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 350640.0, [datetime.datetime(2121, 3, 7, 15, 0), 223758, 2, '']]\n",
      "6 : 113210\n",
      "DUPLICATED : ['cecate', 12300.0, [datetime.datetime(2145, 7, 19, 17, 45), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 12300.0, [datetime.datetime(2145, 7, 19, 17, 45), 223758, 2, '']]\n",
      "7 : 144497\n",
      "8 : 194406\n",
      "DUPLICATED : ['cecate', 23100.0, [datetime.datetime(2138, 7, 14, 17, 10), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 23100.0, [datetime.datetime(2138, 7, 14, 17, 10), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 96720.0, [datetime.datetime(2138, 7, 15, 13, 37), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 96720.0, [datetime.datetime(2138, 7, 15, 13, 37), 223758, 2, '']]\n",
      "9 : 131870\n",
      "10 : 170691\n",
      "11 : 197979\n",
      "12 : 102738\n",
      "13 : 157477\n",
      "14 : 156416\n",
      "DUPLICATED : ['cecate', 8520.0, [datetime.datetime(2145, 8, 17, 1, 23), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 8520.0, [datetime.datetime(2145, 8, 17, 1, 23), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 16620.0, [datetime.datetime(2145, 8, 17, 3, 38), 223758, 2, '']]\n",
      "DUPLICATED : ['cecate', 16620.0, [datetime.datetime(2145, 8, 17, 3, 38), 223758, 2, '']]\n",
      "15 : 122781\n",
      "16 : 137515\n",
      "17 : 135053\n",
      "18 : 130978"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.exists(path+'/log'):\n",
    "    os.makedirs(path+'/log')\n",
    "if not os.path.exists(path+'/dropped'):\n",
    "    os.makedirs(path+'/dropped')\n",
    "    \n",
    "f = open(path+'/log/block-'+str(block),'w')    \n",
    "\n",
    "cmds = admission_ids[block*1000:(block+1)*1000]\n",
    "for i in range(len(cmds)):\n",
    "    aid = cmds[i]\n",
    "    j = block*1000 + i\n",
    "    print str(j) + \" : \" + str(aid)\n",
    "\n",
    "    res1 = processing(aid,f)\n",
    "    np.save(path+'/dropped/adm-'+str(\"%.6d\" % j),{'dropped':res1[1],'id':aid,'i':j})\n",
    "    writeline(f, '--------------------------------------------------------------------------------')\n",
    "    f.flush()\n",
    "\n",
    "print 'DONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
